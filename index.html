<!doctype html>
<html lang="en">
<head>
<title>Your Project Name</title>
<meta property="og:title" content=Jury learning" />
<meta name="twitter:title" content="Jury learning" />
<meta name="description" content="Your project about your cool topic described right here." />
<meta property="og:description" content="Your project about your cool topic described right here." />
<meta name="twitter:description" content="Your project about your cool topic described right here." />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<!-- bootstrap for mobile-friendly layout -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css" integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
<link href="style.css" rel="stylesheet">

</head>
<body class="nd-docs">
<div class="nd-pageheader">
 <div class="container">
 <h1 class="lead">
 <nobr class="widenobr">Jury Learning: Integrating Dissenting Voices into Machine
  Learning Models</nobr>
 </h1>
 </div>
</div><!-- end nd-pageheader -->

<div class="container">
<div class="row">
<div class="col justify-content-center text-center">
<h2>An Analysis of "Jury Learning: Integrating Dissenting Voices into Machine
  Learning Models"</h2>
</div>
</div>
<div class="row">
<div class="col">

<h2>Introduction/Motivation</h2>

<p>Jury Learning introduces a novel approach in supervised machine learning (ML) to address the challenge of label disagreements in societal contexts, such as online toxicity, misinformation detection, and medical diagnosis. Traditional ML methods typically use majority voting to resolve these disagreements, often overshadowing minority perspectives. The innovative solution proposed is 'jury learning,' which explicitly considers diverse societal opinions. This method involves forming a 'jury' of diverse annotators to determine the classifier's predictions, thereby integrating varied viewpoints and responses to societal disagreements. The paper presents a deep learning architecture that models individual annotators, allowing for dynamic jury compositions and enhanced representation of minority views. This approach not only accommodates diverse opinions but also significantly alters classification outcomes,
  indicating its potential for creating more inclusive and representative ML models.
</p>
<div style="text-align:center;">
  <img src="images/jury_learning.PNG" alt="An overview of Jury Learning" width="800" height="400">
      </div>
  <style>
      /* Add some basic styling to arrange image and text side by side */
      .containerImg {
          display: flex;
          align-items: center;
      }
  
      .image-container img {
          width: 200px; /* Adjust the width as needed */
          height: auto;
          margin-right: 20px; /* Add some spacing between image and text */
      }
  </style>

<div class="image-container image1">
  <h2>Biography</h2>
      <div class="containerImg">
  <!--        <div class="image-container image1">-->
          <img src="images/mitchell.png" alt="Mitchell L. Gordon">
  <!--            </div>-->
          <p> <b> Mitchell L. Gordon </b> <br>
              Incoming Assistant Prof. at MIT <br>
              Post Doc from University of Washington <br>
              PhD from Stanford <br>
              Citations: 817 <br>
          </p>
      </div>
      <br>
      <div class="containerImg">
          <img src="images/michelle.png" alt="Michelle S. Lam">
          <p><b> Michelle S. Lam </b> <br>
              PhD candidate at Stanford <br>
              BS and MS from Stanford <br>
              Citations: 237
          </p>
      </div>
      <br>
      <div class="containerImg">
          <img src="images/joon.png" alt="Joon Sung Park">
          <p> <b>Joon Sung Park</b> <br>
              PhD candidate at Stanford <br>
              MS from UIUC <br>
              Citations: 2845 <br>
  
          </p>
      </div>
      <br>
      <div class="containerImg">
          <img src="images/kayur.png" alt="Kayur Patel">
          <p> <b> Kayur Patel </b> <br>
              Research Scientist at Apple <br>
              PhD from University of Washington <br>
              MS from Stanford <br>
              Citations: 1811 <br>
  
          </p>
      </div>
      <br>
      <div class="containerImg">
          <img src="images/jeffrey.png" alt="Jeffrey T. Hancock ">
          <p> <b> Jeffrey T. Hancock </b> <br>
              Professor at Stanford <br>
              Ex Professor at Cornell <br>
              PhD from Dalhousie University <br>
              Citations: 28025 <br>
  
  
          </p>
      </div>
      <br>
      <div class="containerImg">
          <img src="images/tatsunori.png" alt="Tatsunori Hashimoto">
          <p> <b> Tatsunori Hashimoto</b> <br>
  
              Assistant Professor at Stanford <br>
              Post Doc from Stanford University <br>
              PhD from MIT <br>
              Citations: 9577 <br>
          </p>
      </div>
      <br>
      <div class="containerImg">
          <img src="images/michael.png" alt="Michael S. Bernstein">
          <p> <b> Michael S. Bernstein </b> <br>
  
              Associate Professor at Stanford <br>
              MS and PhD from MIT <br>
              Co-author in Image Net <br>
              Citations: 67060 <br>
          </p>
      </div>
      </div>

<h2>Literature Review</h2>
<p>
  <b>Engaging Stakeholders in Algorithm Design: </b> The paper discusses the critique of unexamined majoritarianism in governance, which tends to exclude minority viewpoints. In response to this, jury learning is introduced as a means to control how majorities are formed, raising awareness of the consequences of potential majorities and encouraging intentionality in their selection. This approach aligns with the need in human-computer interaction and AI fairness for algorithms that balance multiple stakeholders' needs and interests. The work builds on advancements in algorithmic fairness, focusing on managing disparate beliefs and emphasizing the inclusion of diverse voices in algorithmic decision-making[1].
</p>
<p>
  <b>Disagreement Datasets and Machine Learning: </b> The paper explores the common practice in machine learning of using large datasets of individual beliefs, often aggregated into a single 'ground truth' label through majority voting. This method, while successful in many AI tasks, has limitations, especially in contexts where societal and cultural disagreements exist. The authors highlight the importance of understanding not just the existence of disagreement but also the nature and reasons behind it. They propose annotator-level modeling to better capture the distribution of opinions and provide insights into who disagrees and why. This approach contrasts with traditional methods that strive for an impartial and supposedly "unbiased" dataset, which may not fully capture the complexity and diversity of societal opinions[2].
</p>
<p>
  <b>Real-Time Exploration and Tuning of Classifier Populations: </b> The paper addresses the practical challenges in machine learning related to the static nature of datasets. Traditional methods often require large-scale data collection whenever the relevant stakeholders change. The jury learning approach, however, allows practitioners to model each relevant individual or group from existing datasets, enabling them to reason over and specify which individuals or groups their models should reflect. This method offers a more dynamic and responsive way of incorporating diverse voices into machine learning models without the need for continually collecting new datasets[3].
</p>

<h2>Methodology</h2>
    <div style="text-align:center;">
        <img src="images/model.png" alt="Model Architecture" width="800" height="300">
    </div>
    <p>
      The authors utilized TensorFlow Recommenders (TFRS) which inherently supports Deep & Cross Networks (DCNs). They incorporated BERTweet, a large-scale language model pre-trained on English Tweets by NVIDIA, via Huggingface’s TensorFlow API for pre-trained content embeddings within their recommender system. The adaptation of the model to the task involved an initial fine-tuning step using a large-scale toxicity dataset released by Jigsaw.

      Initially, the authors co-trained all components of the model: fine-tuning the pre-trained language model and training the annotator embedding, group embeddings, and the DCN from randomly initialized values. Recognizing that BERT-based models tend to overfit after a few epochs of fine-tuning, while the newly initialized components benefit from longer training, they co-trained the entire model for two epochs, then froze the large language model and continued training the rest for eight more epochs. Further training showed no significant improvement in performance.

      Standard hyperparameters for fine-tuning BERT-based models were chosen, including a learning rate of 2e-5, a batch size of 16, and a maximum token length of 128. DCN-specific hyperparameters were set to a constant embedding dimension of 32, a three-layer cross network of size 768, three dense layers of size 768, and an output dense layer of size 1. These parameters were determined after a small grid search.
    </p>


    <div style="text-align:center;">
        <img src="images/user-evaluation.png" alt="User Evaluation" width="800" height="300">
    </div>



<h2>Social Impact</h2>
    <br>

    <h3>Positive Impacts:</h3>
    <ul>
        <li><strong>Fairness:</strong> Provides an orthogonal view of fairness. Fairness in AI has been output-centered but this paper provides an opportunity to include fairness at the model input level.</li>

        <li><strong>Diversity:</strong> Provides a way to include the values of diverse groups of people.</li>

        <li><strong>Inclusion:</strong> Ensures we can hear the voices of underrepresented groups and learn from them.</li>

        <li><strong>Interpretability:</strong> Provides visualizations and model results that are more interpretable.</li>

        <li><strong>Better Decision Making:</strong> ML and HCI Practitioners can visualize results which can lead to better decision making.</li>
    </ul>

    <h3>Negative Impacts:</h3>
    <ul>
        <li><strong>Bias:</strong> Biased Jurors and ML practitioners can create harmful models.</li>

        <li><strong>Privacy:</strong> As it involves a lot of information about the demographics and identity of annotators, it can affect their privacy.</li>

        <li><strong>Abdication of Responsibility:</strong> Who should be held accountable if something goes wrong? ML practitioners, jurors, or companies deploying the model.</li>

        <li><strong>Ecological Fallacy:</strong> We associate attributes on a group with individuals when we take the means of all the juries as the final output.</li>
    </ul>
<h2>Industrial Application</h2>
    <p> Companies can shift the AI models they use to this new paradigm based on Jury Learning. It offers better interpretability, visualization and decision making. Suppose you are a journalist and your comment was removed by a toxicity detection model, you would want to know what about it was toxic. With Jury Learning, the companies can provide a better reasoning like "A jury of 6 people including 2 black women, 2 white women, and 2 asian men found this toxic". </p>
    <p> Companies also don't have to undergo the tedious and time-consuming process of creating ML models for different target population. They can use same model but a jury composition that represents the target population the best. </p>

    <h2>Academic Research</h2>
    <p> Jury learning currently models values and voices of annotators based on their demographics. An intriguing avenue for expanding this research would be implicitly deriving these values and voices from the data, without necessitating explicit demographic information. This would allow models to learn more nuanced values of a person which are not just based on their identity or demographics.  Consider a dietitian striving to suggest the optimal food items for a person. Employing a "jury learning" model with implicit values learning that learns from  past data of  the target individual and comparable profiles would help in making food items suggestion based on preferences and values of the individual. This nuanced approach would help us build human-centric ML models that are grounded in values and preferences.</p>
<h2>Peer-Review</h2>
    <br>

    <h3> Reviewer 1 (Akshat Choube)</h3> <br>
    <p> <b> Score: 7 (Accept)</b></p>
    <p> <b> Strengths </b></p>
    <ul>
        <li>Introduces a new architecture that combines Deep Cross Networks with LLMs</li>
        <li>Jointly modelling annotators
            and the task is unique</li>
        <li>Introduces a new learning framework that is more grounded in human values</li>
        <li>Makes the model more explainable and offers better decision-making for ML practitioners</li>
    </ul>

    <p> <b> Weakness </b></p>
    <ul>
        <li>The paper missed the in-detail discussion of the applicability of “Jury Learning” in other domains.</li>
        <li>The authors should have discussed in more detail the limitations of this framework.</li>
        <li>Jury selection is an important aspect of this paper, and authors should have discussed a more algorithmic approach to it.</li>
        <li>Some parts of the paper were repetitive.</li>
    </ul>

<h3>References</h3>


<p><a name="bottou-1990">[1]</a> <a href="https://papers.baulab.info/Bottou-1990.pdf"
  >L&eacute;on Bottou and Patrick Gallinari.
  <em>A framework for the cooperation of learning algorithms.</em></a>
  Advances in neural information processing systems 3 (1990).
</p>

<h2>Team Members</h2>

<p>Srijha Kalyan</p>
<p>Akshat Choube</p>



</div><!--col-->
</div><!--row -->
</div> <!-- container -->

<footer class="nd-pagefooter">
  <div class="row">
    <div class="col-6 col-md text-center">
      <a href="https://cs7150.baulab.info/">About CS 7150</a>
    </div>
  </div>
</footer>

</body>
<script>
$(document).on('click', '.clickselect', function(ev) {
  var range = document.createRange();
  range.selectNodeContents(this);
  var sel = window.getSelection();
  sel.removeAllRanges();
  sel.addRange(range);
});
// Google analytics below.
window.dataLayer = window.dataLayer || [];
</script>
</html>
